?matrix
lambda = 0.2
n = 40
nsim = 1000
rexp_random <- rexp(n = n*nsim, rate = lambda)
rexp_averages <- apply(matrix(data = rexp(n*nsim, lambda), nrow = nsim), 2, mean)
str(rexp_averages)
lambda = 0.2
n = 40
nsim = 1000
rexp_random <- rexp(n = n*nsim, rate = lambda)
rexp_averages <- apply(matrix(data = rexp(n*nsim, lambda), nrow = n), 2, mean)
str(rexp_averages)
swirl()
include(swirl)
import(swirl)
require(swirl)
swirl()
exit()
0
exit
matrix(rexp(40*1000, 0.2), 40)
m <- matrix(rexp(40*1000, 0.2), 40)
q
q()
bye()
m <- matrix(rexp(40*1000, 0.2), 40)
m
str(m)
m <- as.matrix(m)
str(m)
m <- matrix(data=rexp(40*1000, 0.2), 1000, 40)
str(m)
a <- apply(m, 1, mean)
str(a)
plot(a)
hist(a)
sd(a)
5/40
5/sqrt(40)
5/sqrt(1000)
- Sample variance is $\Big(\frac{sd(rexp\_random)}{\sqrt{nsim}}\Big)^2$ which gives `r round((sd(rexp_random)/sqrt(nsim))^2, 4)` and `r var(rexp_random)`
- Sample variance is $\Big(\frac{sd(rexp\_random)}{\sqrt{nsim}}\Big)^2$ which gives `r round((sd(rexp_random)/sqrt(nsim))^2, 4)` and `r Var(rexp_random)`
- Sample variance is $\Big(\frac{sd(rexp\_random)}{\sqrt{nsim}}\Big)^2$ which gives `r round((sd(rexp_random)/sqrt(nsim))^2, 4)`
set.seed(2121)
lambda = 0.2
n = 40
nsim = 1000
rexp_random <- rexp(n = nsim, rate = lambda)
rexp_averages <- apply(matrix(rexp(n*nsim, lambda), nrow = nsim, ncol = n), 1, mean)
plot(rexp_random)
hist(rexp_random)
hist(rexp_averages)
sd(rexp_averages)
sd(rexp_random)
5/sqrt(40)
5/sqrt(1000)
sd(rexp_random)/sqrt(1000)
sd(rexp_averages)/sqrt(1000)
sd(rexp_averages)
sd(rexp_averages)/sqrt(40)
5/sqrt(1000)
5/sqrt(40)
25/40
0.81^2
datasets(ToothGrowth)
dataset(ToothGrowth)
library(datasets)
d <- ToothGrowth
str(d)
?ToothGrowth
library(ggplot2)
install.packages("caret")
library(caret)
library(kernlab)
data("spam")
inTrain <- createDataPartition(y=spam$type, p = 0.75, list = FALSE)
training <- [inTrain,]
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~ ., data = training, method = "glm")
install.packages('caret', dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
modelFit <- train(type ~ ., data = training, method = "glm")
library(caret)
library(kernlab)
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit
modelFit$results
modelFit$finalModel
predictions <- predict(modelFit, newdata=testing)
predictions
confusionMatrix(predictions, testing$type)
library(AppliedPredictiveModeling)
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(training$CompressiveStrength)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength, colour = training$Cement)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength, colour = .)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength, colour = training$Age)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength, colour = training$FlyAsh)
qplot(training$Superplasticizer)
qplot(log10(training$Superplasticizer))
qplot(log10(training$Superplasticizer + 1))
qplot(training$Superplasticizer)
qplot(training$Superplasticizer == 0)
qplot(training$Superplasticizer)
qplot(log10(training$Superplasticizer))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training[,grep("IL",colnames(training))]
training[,grep("^IL",colnames(training))]
finModel <- train(training$diagnosis ~ training[,grep("^IL",colnames(training))], method="glm", preProcess="pca")
finModel <- train(training$diagnosis ~ sum(training[,grep("^IL",colnames(training))]), method="glm", preProcess="pca")
finModel <- train(training$diagnosis ~ colnames(training[,grep("^IL",colnames(training))]), method="glm", preProcess="pca")
colnames(training[,grep("^IL",colnames(training))])
finModel <- train(diagnosis ~ colnames(training[,grep("^IL",colnames(training))]), method="glm", preProcess="pca", data=training)
finModel <- train(diagnosis ~ paste(colnames(training[,grep("^IL",colnames(training))], sep ="+"), method="glm", preProcess="pca", data=training)
d
finModel <- train(diagnosis ~ paste(colnames(training[,grep("^IL",colnames(training))], sep ="+")), method="glm", preProcess="pca", data=training)
finModel <- train(diagnosis ~ paste(colnames(training[,grep("^IL",colnames(training))]), sep ="+"), method="glm", preProcess="pca", data=training)
paste(colnames(training[,grep("^IL",colnames(training))]), sep ="+")
colnames(training[,grep("^IL",colnames(training))])
paste(colnames(training[,grep("^IL",colnames(training))]), sep ="+")
paste(colnames(training[,grep("^IL",colnames(training))]), sep = "",
collapse = " + ")
finModel <- train(diagnosis ~ paste(colnames(training[,grep("^IL",colnames(training))]), sep = "", collapse = " + "), method="glm", preProcess="pca", data=training)
finModel <- train(as.formula(diagnosis ~ paste(colnames(training[,grep("^IL",colnames(training))]), sep = "", collapse = " + ")), method="glm", preProcess="pca", data=training)
as.formula(diagnosis ~ paste(colnames(training[,grep("^IL",colnames(training))]), sep = "", collapse = " + "))
formula <- as.formula(training$diagnosis ~ paste(colnames(training[,grep("^IL",colnames(training))]), sep = "", collapse = " + "))
formula
predictors <- paste(colnames(training[,grep("^IL",colnames(training))]), sep = "", collapse = " + ")
finModel <- train(as.formula(diagnosis ~ predictors), method="glm", preProcess="pca", data=training)
as.formula(diagnosis ~ predictors)
finModel <- train(diagnosis ~ predictors, method="glm", preProcess="pca", data=training)
predictors
finModel <- train(diagnosis ~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", data=training)
preProc <- preProcess(training[,colnames(training[,grep("^IL",colnames(training))])], method = "pca")
preProc
preProc <- preProcess(training[,colnames(training[,grep("^IL",colnames(training))])], method = "pca", pcaComp = 5)
preProc
summary(preProc)
preProc$rotation
preProc <- preProcess(training[,colnames(training[,grep("^IL",colnames(training))])], method = "pca", thresh = 0.9)
preProc$rotation
data("iris")
library(ggplot2)
library(caret)
inTrain <- createDataPartition(iris$Species, p=0.7, list=F)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
qplot(iris$Sepal.Length,iris$Sepal.Width, colour=iris$Species)
qplot(iris$Petal.Length,iris$Sepal.Width, colour=iris$Species)
modFit <- train(iris$Species ~ ., method = "rpart")
modFit <- train(iris$Species ~ ., method = "rpart", data=training)
modFit <- train(Species ~ ., method = "rpart", data=training)
confusionMatrix(modFit$finalModel, training$Species)
modFit$pred
modFit$finalModel
modFit$method
plot(modFit$finalModel)
plot(modFit$finalModel, uniform = T)
plot(modFit$finalModel)
text(modFit$finalModel, use.n = T, all = T)
text(modFit$finalModel, use.n = T, all = T, cex=0.35)
plot(modFit$finalModel)
text(modFit$finalModel, use.n = T, all = T, cex=0.75)
library(rattle)
install.packages("rattle")
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
pred <- predict(modFit, newdata = testing)
pred
library(caret)
pred <- predict(modFit, newdata = testing)
pred
confusionMatrix(pred, testing$Species)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("ozone", package = "ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
str(ozone)
data("iris")
library(ggplot2)
library(caret)
inTrain <- createDataPartition(iris$Species, p=0.7, list = F)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
model <- train(Species ~ ., method = "rf", data = training, prox = T)
model
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(segmentationOriginal$Case, p=0.7, list=F)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
model <- train(Case ~ ., method="rpart", data=training)
aPred <- predict(model, newdata = c("TotalIntench2" = 23000, "FiberWidthCh"1 = 10, "PerimStatusCh1" =2))
aPred <- predict(model, newdata = c("TotalIntench2" = 23000, "FiberWidthCh"1 = 10, "PerimStatusCh1" = 2))
str(segmentationOriginal)
c("TotalIntench2" = 23000, "FiberWidthCh"1 = 10, "PerimStatusCh1" = 2)
aPred <- predict(model, newdata = c("TotalIntench2" = 23000, "FiberWidthCh1" = 10, "PerimStatusCh1" = 2))
c("TotalIntench2" = 23000, "FiberWidthCh" = 10, "PerimStatusCh1" = 2)
c("TotalIntench2" = 23000, "FiberWidthCh1" = 10, "PerimStatusCh1" = 2)
a <- c("TotalIntench2" = 23000, "FiberWidthCh1" = 10, "PerimStatusCh1" = 2)
aPred <- predict(model, newdata = a)
inTrain <- createDataPartition(segmentationOriginal$Case == train, list=F)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
model <- train(Class ~ ., method="rpart", data=training)
aPred <- predict(model, newdata = a)
str(model$finalModel)
aPred <- predict(model, newdata = testing[a,])
aPred
testing[a,]
atr(testing[a,])
str(testing[a,])
aPred <- predict(model, newdata = testing[TotalIntench2 = 23000 & FiberWidthCh1 = 10 & PerimStatusCh1=2,])
aPred <- predict(model, newdata = testing[TotalIntench2 =+ 23000 & FiberWidthCh1 == 10 & PerimStatusCh1 == 2,])
aPred <- predict(model, newdata = testing[TotalIntench2 == 23000 & FiberWidthCh1 == 10 & PerimStatusCh1 == 2,])
aPred <- predict(model, newdata = testing[testing$TotalIntench2 == 23000 & testing$FiberWidthCh1 == 10 & testing$PerimStatusCh1 == 2,])
aPred
str(segmentationOriginal$TotalIntenCh2)
aPred <- predict(model, newdata = testing[testing$TotalIntenCh2 == 23000 & testing$FiberWidthCh1 == 10 & testing$PerimStatusCh1 == 2,])
aPred
segmentationOriginal[segmentationOriginal$TotalIntenCh2 == 23000,]
nrows(segmentationOriginal[segmentationOriginal$TotalIntenCh2 == 23000,])
nrow(segmentationOriginal[segmentationOriginal$TotalIntenCh2 == 23000,])
aPred <- predict(model, newdata = a)
a
a <- a + c(Cell = NA)
a
a <- c(Cell = NA, TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1 = 2)
a
aPred <- predict(model, newdata = a)
aPred <- predict.rpart(model, newdata = a)
aPred <- predict(model, newdata = testing)
confusionMatrix(aPred, testing$Class)
aPred <- predict(model$finalModel, newdata = a)
aPred <- predict(model$finalModel, newdata = a,  type = "class")
aPred <- predict(model$finalModel, newdata = a, type = "class")
a <- as.data.frame(a)
a <- a[,-c("Cell")]
a
a <- c(TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1 = 2)
a <- data.frame(as.list(a))
a
aPred <- predict(model, newdata = a)
aPred <- predict(model$finalModel, newdata = a)
predictors(model)
colnames(testing)
a <- data.frame(colnames=(colnames(testing)))
a
a <- data.frame()
colnames(a) <- colnames(testing)
a <- as.data.frame(setNames(colnames(testing)))
a <- data.frame(colnames(testing) = NA)
a <- data.frame(c(colnames(testing)))
a <- colnames(testing)
a <- data.frame(as.list(a))
a
str(a)
a <- data.frame(as.list(colnames(testing)))
str(a)
as.list(c("test"))
colnames(a)
colnames(a) <- gsub("X.", ".", colnames(a))
str(a)
colnames(a) <- gsub(".", "", colnames(a))
str(a)
colnames(a)
a <- data.frame(rep(numeric(0), 119))
rep(numeric(0), 119)
c(rep(numeric(0), 119))
c(rep(numeric(0), 1:119))
c(numeric, length(119))
c(numeric(0), length(119))
vector(numeric(0), length(119))
vector(numerical, 119)
vector(numeric, 119)
vector("numeric", 119)
a <- vector("numeric", 119)
a <- NA
a
a <- vector("numeric", 119)
colnames(a) <- colnames(testing)
rep(NA, 119)
as.data.frame(rbind(colnames(testing),rep(NA, 119))
)
a <- as.data.frame(rbind(colnames(testing),rep(NA, 119)))
str(a)
a <- as.data.frame(rep(NA, 119))
str(a)
a <- as.data.frame(as.list(rep(NA, 119)))
str(a)
a <- as.data.frame(matrix(nrow = 0, ncol = 119, dimnames = colnames(testing)))
a <- as.data.frame(matrix(nrow = 0, ncol = 119, dimnames = as.list(colnames(testing))))
a <- as.data.frame(matrix(nrow = 0, ncol = 119))
colnames(a) <- colnames(testing)
str(a)
View(testing)
str(testing)
a <- testing[1,]
str(a)
a[1,] <- NA
str(a)
a$TotalIntenCh2 <- 23000
a$FiberWidthCh1 <- 10
a$PerimStatusCh1 <- 2
predict(model, newdata = a)
predict(model, newdata = a)[0]
predict(model, a)
predict(model$finalModel, a)
predict(model, a)
aPred <- predict(model, a)
aPred
str(testing$TotalIntenCh2)
b <- testing[1,]
b[1,] <- NA
b$TotalIntenCh2 <- 50000
b$FiberWidthCh1 <- 10
b$VarIntenCh4 <- 100
bPred <- predict(model, b)
bPred
model <- train(Class ~ ., method="rpart", data = training)
bPred <- predict(model, b)
model$finalModel
library(slidify)
author("test")
slidify("index.Rmd")
slidify("index.Rmd")
load("~/apps/datasci/ml_assign/.RData")
View(inTrain)
View(inTrain)
str(testing)
training2 <- training[sapply(training, function(x) !any(is.na(x)))]
remove_cols <- grepl("X|user_name|timestamp", colnames(training))
training <- training2[,!remove_cols]
remove_cols <- grepl("X|user_name|timestamp", colnames(training2))
training2 <- training2[,!remove_cols]
str(training2)
training <- training[sapply(training, function(x) !any(is.na(x)))]
remove_cols <- grepl("X|user_name|timestamp", colnames(training))
training <- training[,!remove_cols]
str(training)
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
getwd()
setwd("~/apps/datasci/ml_assign")
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
training <- training[sapply(training, function(x) !any(is.na(x)))]
remove_cols <- grepl("X|user_name|timestamp", colnames(training))
training <- training[,!remove_cols]
str(training)
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
small_training <- training[sapply(training, function(x) !any(is.na(x)))]
remove_cols <- grepl("X|user_name|timestamp", colnames(small_training))
small_training <- small_training[,!remove_cols]
str(small_training)
small_testing <- testing[,colnames(small_training)]
colnames(small_training) == colnames(testing)
colnames(small_training)
testing[,colnames(small_training)]
vec <- colnames(small_training)
testing[,vec]
vec
testing[,c(vec)]
testing[,c(1,2)]
testing[,c("X", "user_name")]
str(vec)
testing[,c("user_name")]
testing[,vec]
col_names <- vec[vec != "classe"]
testing[,c(col_names, 160)]
testing[,c(col_names, "problem_id")]
str(testing[,c(col_names, "problem_id")])
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
# 6. columns with NAs
training <- training[sapply(training, function(x) !any(is.na(x)))]
# 7. additional columns to remove (X, user_name and timestamps)
remove_cols <- grepl("X|user_name|timestamp", colnames(training))
training <- training[,!remove_cols]
# 8. apply the same reduction to testing dataset (except last column)
col_names <- colnames(training)[colnames(training) != "classe"]
testing <- testing[, c(col_names, "problem_id")]
# 9. split data
inTrain <- createDataPartition(training$classe, p=0.7, list=F)
train <- training[inTrain,]; test <- testing
validate <- training[-inTrain,]
library(caret)
# 9. split data
inTrain <- createDataPartition(training$classe, p=0.7, list=F)
train <- training[inTrain,]; test <- testing
validate <- training[-inTrain,]
model <- train(classe ~ ., method="rf", data=train)
# 6. columns with NAs
training <- training[sapply(training, function(x) !any(is.na(x)))]
# 7. additional columns to remove (X, user_name and timestamps)
remove_cols <- grepl("X|user_name|timestamp|window", colnames(training))
training <- training[,!remove_cols]
# 8. apply the same reduction to testing dataset (except last column)
col_names <- colnames(training)[colnames(training) != "classe"]
testing <- testing[, c(col_names, "problem_id")]
# 9. split data
inTrain <- createDataPartition(training$classe, p=0.7, list=F)
train <- training[inTrain,]; test <- testing
validate <- training[-inTrain,]
near_zero <- nearZeroVar(training[sapply(training, is.numeric)], saveMetrics = TRUE)
str(near_zero)
training = training[,near_zero[, 'nzv']==FALSE]
training[sapply(training, is.numeric)]
str(training[sapply(training, is.numeric)])
near_zero
cor_matrix <- cor(na.omit(training[sapply(training, is.numeric)]))
rm_cor <- findCorrelation(cor_matrix, cutoff = .90, verbose = F)
training <- training[,-rm_cor]
col_names <- colnames(training)[colnames(training) != "classe"]
testing <- testing[, c(col_names, "problem_id")]
inTrain <- createDataPartition(training$classe, p=0.7, list=F)
train <- training[inTrain,]
validate <- training[-inTrain,]
test <- testing
model <- train(classe ~ ., method="rf", data=train)
preProc <- preProcess(train[, -46], method = "pca", thresh = 0.99)
preProc
summary(preProc)
preProc <- preProcess(train[, -46], method = "pca", thresh = 0.95)
preProc
train_pca <- predict(preProc, train[, -46])
validate_pca <- predict(preProc, validate[, -46])
model <- train(classe ~ ., method="rf", data=train_pca)
model <- train(train$classe ~ ., method="rf", data=train_pca)
model <- train(train$classe ~ ., method="rf", data=train_pca, trControl = trainControl(method = "cv", number = 4), importance = TRUE)
summary(model)
cros_valid <- predict(model, validate_pca)
confusionMatrix(validate$classe, cros_valid)$table
confusionMatrix(validate$classe, cros_valid)
confusionMatrix(validate$classe, cros_valid)$Accuracy
conf <- confusionMatrix(validate$classe, cros_valid)
conf$overall
conf$overall["Accuracy"]
conf$overall["Accuracy"][0]
conf$overall["Accuracy"][1]
conf$overall["Accuracy"][[1]]
